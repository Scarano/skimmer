{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97260064-5000-4822-8600-34a7136612de",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1ac2b7b70f44a595048e528dc8bf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 17:31:28 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-12-01 17:31:29 INFO: File exists: /Users/sam/stanza_resources/en/default.zip\n",
      "2023-12-01 17:31:33 INFO: Finished downloading models and saved to /Users/sam/stanza_resources.\n",
      "2023-12-01 17:31:34 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | spacy               |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2023-12-01 17:31:34 INFO: Using device: cpu\n",
      "2023-12-01 17:31:34 INFO: Loading: tokenize\n",
      "2023-12-01 17:31:34 INFO: Loading: pos\n",
      "2023-12-01 17:31:35 INFO: Loading: lemma\n",
      "2023-12-01 17:31:35 INFO: Loading: constituency\n",
      "2023-12-01 17:31:35 INFO: Loading: depparse\n",
      "2023-12-01 17:31:35 INFO: Loading: sentiment\n",
      "2023-12-01 17:31:35 INFO: Loading: ner\n",
      "2023-12-01 17:31:36 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Download the language model\n",
    "stanza.download('en')\n",
    "\n",
    "# Build a Neural Pipeline\n",
    "pipeline = stanza.Pipeline('en', processors = {'tokenize': 'spacy',\n",
    "                                                    # 'mwt': 'default',\n",
    "                                                    'pos': 'default',\n",
    "                                                    'lemma': 'default',\n",
    "                                                    'depparse': 'default'},\n",
    "                                        download_method=stanza.DownloadMethod.REUSE_RESOURCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2edba0d3-d0e9-4a0e-a6cd-7a1ceec5b416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading in shares of WeWork were halted Monday as rumors swirl that the office sharing company, once valued as high as $47 billion, will seek bankruptcy protection.\n",
      "\n",
      "Last week, The Wall Street Journal and other media outlets reported that WeWork was planning to file for Chapter 11 bankrutpcy protection as early as this week — citing unnamed sources familiar with the matter.\n",
      "\n",
      "A WeWork spokesperson said last week that the company does not comment on speculation and did not immediately return messages after trading in the company’s stock was halted Monday.\n",
      "\n",
      "Shares of WeWork, which cost more than $400 two years ago, could be had Monday for less than $1.\n",
      "\n",
      "WeWork is paying the price for aggressive expansion in its early years.\n",
      "\n",
      "The company went public in October 2021 after its first attempt to do so two years earlier collapsed spectacularly.\n",
      "\n",
      "The debacle led to the ouster of founder and CEO Adam Neumann, whose erratic behavior and exorbitant spending spooked early investors.\n",
      "\n",
      "Japan’s SoftBank stepped in to keep WeWork afloat, acquiring majority control over the company.\n",
      "\n",
      "Despite efforts to turn the company around since Neumann’s departure — including significant cuts to operating costs and rising revenue — WeWork has struggled in a commercial real estate market that has been rocked by the rising costs of borrowing money, as well as a shifting dynamic for millions of office workers now checking into their offices remotely.\n",
      "\n",
      "In September, when WeWork announced plans to renegotiate nearly all of its leases, CEO David Tolley noted that the company’s lease liabilities accounted for more than two-thirds of its operating expenses for the second quarter of this year — remaining “too high” and “dramatically out of step with current market conditions.”\n",
      "\n",
      "Last month, WeWork skipped hefty interest payments — kicking off a 30-day grace period before an event of default.\n",
      "\n",
      "And last week, WeWork disclosed a forbearance agreement with bondholders that extended negotiations by one week prior to triggering a default.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/sam/programs/skimmer/dev-data/test01.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "for sent in pipeline(text).sentences:\n",
    "    print(sent.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab71a80-007b-4bbb-bb04-3ecc195f336a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 4, 'det')\n",
      "('most', 3, 'advmod')\n",
      "('bizarre', 4, 'amod')\n",
      "('thing', 8, 'nsubj')\n",
      "('in', 7, 'case')\n",
      "('the', 7, 'det')\n",
      "('world', 4, 'nmod')\n",
      "('happened', 0, 'root')\n",
      "('to', 10, 'case')\n",
      "('me', 8, 'obl')\n",
      "('.', 8, 'punct')\n",
      "Token           | Relation   | Head            \n",
      "--------------------------------------------------\n",
      "The             | det        | thing           \n",
      "most            | advmod     | bizarre         \n",
      "bizarre         | amod       | thing           \n",
      "thing           | nsubj      | happened        \n",
      "in              | case       | world           \n",
      "the             | det        | world           \n",
      "world           | nmod       | thing           \n",
      "happened        | root       | ROOT            \n",
      "to              | case       | me              \n",
      "me              | obl        | happened        \n",
      ".               | punct      | happened        \n"
     ]
    }
   ],
   "source": [
    "# text = 'JetBlue canceled our flight this morning which was already late.'\n",
    "# text = \"When he first met the FTX founder Sam Bankman-Fried in late 2021, he took the cargo-shorted chief executive on a walk through the eucalyptus trees near his Berkeley, Calif., home.\"\n",
    "text = 'The most bizarre thing in the world happened to me.'\n",
    "\n",
    "# Pass the sentence through the pipeline\n",
    "parsed = pipeline(text)\n",
    "\n",
    "# Print the dependencies of the first sentence in the doc object\n",
    "# Format - (Token, Index of head, Nature of dependency)\n",
    "# Index starts from 1, 0 is reserved for ROOT\n",
    "for sent in parsed.sentences:\n",
    "    sent.print_dependencies()\n",
    "\n",
    "\n",
    "print(\"{:<15} | {:<10} | {:<15} \".format('Token', 'Relation', 'Head'))\n",
    "print(\"-\" * 50)\n",
    "  \n",
    "# Convert sentence object to dictionary  \n",
    "sent_dict = parsed.sentences[0].to_dict()\n",
    "\n",
    "# iterate to print the token, relation and head\n",
    "for word in sent_dict:\n",
    "  print (\"{:<15} | {:<10} | {:<15} \"\n",
    "         .format(str(word['text']),str(word['deprel']), str(sent_dict[word['head']-1]['text'] if word['head'] > 0 else 'ROOT')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b96ab80f-b0e9-4824-9e81-3d8f16b61fe0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_deprel', '_deps', '_end_char', '_feats', '_head', '_id', '_is_null', '_lemma', '_misc', '_parent', '_sent', '_start_char', '_text', '_upos', '_xpos', 'add_property', 'deprel', 'deps', 'end_char', 'feats', 'head', 'id', 'lemma', 'misc', 'parent', 'pos', 'pretty_print', 'sent', 'start_char', 'text', 'to_conll_text', 'to_dict', 'upos', 'xpos']\n",
      "    1 When     : 4 advmod\n",
      "    2 he       : 4 nsubj\n",
      "    3 first    : 4 advmod\n",
      "    4 met      : 17 advcl\n",
      "    5 the      : 7 det\n",
      "    6 FTX      : 7 compound\n",
      "    7 founder  : 4 obj\n",
      "    8 Sam      : 7 appos\n",
      "    9 Bankman  : 8 flat\n",
      "   10 -        : 11 punct\n",
      "   11 Fried    : 8 flat\n",
      "   12 in       : 14 case\n",
      "   13 late     : 14 amod\n",
      "   14 2021     : 4 obl\n",
      "   15 ,        : 4 punct\n",
      "   16 he       : 17 nsubj\n",
      "   17 took     : 0 root\n",
      "   18 the      : 23 det\n",
      "   19 cargo    : 21 compound\n",
      "   20 -        : 19 punct\n",
      "   21 shorted  : 23 amod\n",
      "   22 chief    : 23 amod\n",
      "   23 executive: 17 obj\n",
      "   24 on       : 26 case\n",
      "   25 a        : 26 det\n",
      "   26 walk     : 17 obl\n",
      "   27 through  : 30 case\n",
      "   28 the      : 30 det\n",
      "   29 eucalyptus: 30 amod\n",
      "   30 trees    : 26 nmod\n",
      "   31 near     : 37 case\n",
      "   32 his      : 37 nmod:poss\n",
      "   33 Berkeley : 37 compound\n",
      "   34 ,        : 35 punct\n",
      "   35 Calif.   : 33 appos\n",
      "   36 ,        : 33 punct\n",
      "   37 home     : 30 nmod\n",
      "   38 .        : 17 punct\n"
     ]
    }
   ],
   "source": [
    "#sent_dict\n",
    "print(dir(parsed.sentences[0].words[0]))\n",
    "for w in parsed.sentences[0].words:\n",
    "    print(f'{w.id:5} {w.text:9}: {w.head} {w.deprel}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d11d39-fc8b-42e8-8c1f-e24a6872617e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 4,\n",
       " 2: 4,\n",
       " 3: 4,\n",
       " 4: 17,\n",
       " 5: 7,\n",
       " 6: 7,\n",
       " 7: 4,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 10: 11,\n",
       " 11: 8,\n",
       " 12: 14,\n",
       " 13: 14,\n",
       " 14: 4,\n",
       " 15: 4,\n",
       " 16: 17,\n",
       " 17: 0,\n",
       " 18: 23,\n",
       " 19: 21,\n",
       " 20: 19,\n",
       " 21: 23,\n",
       " 22: 23,\n",
       " 23: 17,\n",
       " 24: 26,\n",
       " 25: 26,\n",
       " 26: 17,\n",
       " 27: 30,\n",
       " 28: 30,\n",
       " 29: 30,\n",
       " 30: 26,\n",
       " 31: 37,\n",
       " 32: 37,\n",
       " 33: 37,\n",
       " 34: 35,\n",
       " 35: 33,\n",
       " 36: 33,\n",
       " 37: 30,\n",
       " 38: 17}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_map = {w.id: w.head for w in parsed.sentences[0].words}\n",
    "head_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34ce2c39-6331-4522-8618-bc600ecaeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Iterable\n",
    "\n",
    "def reverse_dict(d):\n",
    "    reversed_dict = {}\n",
    "    for key, value in d.items():\n",
    "        reversed_dict.setdefault(value, []).append(key)\n",
    "    return reversed_dict\n",
    "\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def dfs(node: T, visited: set[T], graph: dict[T, set[T]]):\n",
    "    visited.add(node)\n",
    "    for neighbor in graph.get(node, []):\n",
    "        if neighbor not in visited:\n",
    "            dfs(neighbor, visited, graph)\n",
    "\n",
    "def transitive_closure(d: dict[T, set[T]], keys: Iterable[T]) -> dict[T, set[T]]:\n",
    "    \"\"\"\n",
    "    :param d: Dict defining relation defining the transitive closure. (a, b) is in the relation\n",
    "        iff `b in d[a]`.\n",
    "    :param keys: Keys desired in result\n",
    "    :return: Dict mapping each key in keys to the transitive closure of the key\n",
    "    \"\"\"\n",
    "\n",
    "    closure = {}\n",
    "    for key in keys:\n",
    "        visited = {key}\n",
    "        dfs(key, visited, d)\n",
    "        closure[key] = visited\n",
    "    return closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a4dfb35-6974-4786-a78d-5788cbf772b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [17],\n",
      " 4: [1, 2, 3, 7, 14, 15],\n",
      " 7: [5, 6, 8],\n",
      " 8: [9, 11],\n",
      " 11: [10],\n",
      " 14: [12, 13],\n",
      " 17: [4, 16, 23, 26, 38],\n",
      " 19: [20],\n",
      " 21: [19],\n",
      " 23: [18, 21, 22],\n",
      " 26: [24, 25, 30],\n",
      " 30: [27, 28, 29, 37],\n",
      " 33: [35, 36],\n",
      " 35: [34],\n",
      " 37: [31, 32, 33]}\n",
      "{1: {1},\n",
      " 2: {2},\n",
      " 3: {3},\n",
      " 4: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15},\n",
      " 5: {5},\n",
      " 6: {6},\n",
      " 7: {5, 6, 7, 8, 9, 10, 11},\n",
      " 8: {8, 9, 10, 11},\n",
      " 9: {9},\n",
      " 10: {10},\n",
      " 11: {10, 11},\n",
      " 12: {12},\n",
      " 13: {13},\n",
      " 14: {12, 13, 14},\n",
      " 15: {15},\n",
      " 16: {16},\n",
      " 17: {1,\n",
      "      2,\n",
      "      3,\n",
      "      4,\n",
      "      5,\n",
      "      6,\n",
      "      7,\n",
      "      8,\n",
      "      9,\n",
      "      10,\n",
      "      11,\n",
      "      12,\n",
      "      13,\n",
      "      14,\n",
      "      15,\n",
      "      16,\n",
      "      17,\n",
      "      18,\n",
      "      19,\n",
      "      20,\n",
      "      21,\n",
      "      22,\n",
      "      23,\n",
      "      24,\n",
      "      25,\n",
      "      26,\n",
      "      27,\n",
      "      28,\n",
      "      29,\n",
      "      30,\n",
      "      31,\n",
      "      32,\n",
      "      33,\n",
      "      34,\n",
      "      35,\n",
      "      36,\n",
      "      37,\n",
      "      38},\n",
      " 18: {18},\n",
      " 19: {19, 20},\n",
      " 20: {20},\n",
      " 21: {19, 20, 21},\n",
      " 22: {22},\n",
      " 23: {18, 19, 20, 21, 22, 23},\n",
      " 24: {24},\n",
      " 25: {25},\n",
      " 26: {32, 33, 34, 35, 36, 37, 24, 25, 26, 27, 28, 29, 30, 31},\n",
      " 27: {27},\n",
      " 28: {28},\n",
      " 29: {29},\n",
      " 30: {32, 33, 34, 35, 36, 37, 27, 28, 29, 30, 31},\n",
      " 31: {31},\n",
      " 32: {32},\n",
      " 33: {33, 34, 35, 36},\n",
      " 34: {34},\n",
      " 35: {34, 35},\n",
      " 36: {36},\n",
      " 37: {32, 33, 34, 35, 36, 37, 31},\n",
      " 38: {38}}\n",
      "  1 When      : advmod     When\n",
      "  2 he        : nsubj      he\n",
      "  3 first     : advmod     first\n",
      "  4 met       : advcl      When he first met the FTX founder Sam Bankman - Fried in late 2021 ,\n",
      "  5 the       : det        the\n",
      "  6 FTX       : compound   FTX\n",
      "  7 founder   : obj        the FTX founder Sam Bankman - Fried\n",
      "  8 Sam       : appos      Sam Bankman - Fried\n",
      "  9 Bankman   : flat       Bankman\n",
      " 10 -         : punct      -\n",
      " 11 Fried     : flat       - Fried\n",
      " 12 in        : case       in\n",
      " 13 late      : amod       late\n",
      " 14 2021      : obl        in late 2021\n",
      " 15 ,         : punct      ,\n",
      " 16 he        : nsubj      he\n",
      " 17 took      : root       When he first met the FTX founder Sam Bankman - Fried in late 2021 , he took the cargo - shorted chief executive on a walk through the eucalyptus trees near his Berkeley , Calif. , home .\n",
      " 18 the       : det        the\n",
      " 19 cargo     : compound   cargo -\n",
      " 20 -         : punct      -\n",
      " 21 shorted   : amod       cargo - shorted\n",
      " 22 chief     : amod       chief\n",
      " 23 executive : obj        the cargo - shorted chief executive\n",
      " 24 on        : case       on\n",
      " 25 a         : det        a\n",
      " 26 walk      : obl        on a walk through the eucalyptus trees near his Berkeley , Calif. , home\n",
      " 27 through   : case       through\n",
      " 28 the       : det        the\n",
      " 29 eucalyptus: amod       eucalyptus\n",
      " 30 trees     : nmod       through the eucalyptus trees near his Berkeley , Calif. , home\n",
      " 31 near      : case       near\n",
      " 32 his       : nmod:poss  his\n",
      " 33 Berkeley  : compound   Berkeley , Calif. ,\n",
      " 34 ,         : punct      ,\n",
      " 35 Calif.    : appos      , Calif.\n",
      " 36 ,         : punct      ,\n",
      " 37 home      : nmod       near his Berkeley , Calif. , home\n",
      " 38 .         : punct      .\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "rev_map = reverse_dict(head_map)\n",
    "pprint(rev_map)\n",
    "\n",
    "constituent_map = transitive_closure(rev_map, head_map.keys())\n",
    "pprint(constituent_map)\n",
    "\n",
    "words = parsed.sentences[0].words\n",
    "for w in words:\n",
    "    if w.id not in constituent_map: continue\n",
    "    cons = constituent_map[w.id]\n",
    "    cons_text = ' '.join(words[c-1].text for c in sorted(cons))\n",
    "    print(f\"{w.id:3} {w.text:10}: {w.deprel:10} {cons_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a084298-d111-4160-bb3f-98706ba12458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When he first met the FTX founder Sam Bankman-Fried in late 2021, he took the cargo-shorted chief executive on a walk through the eucalyptus trees near his Berkeley, Calif., home.\n"
     ]
    }
   ],
   "source": [
    "print(parsed.sentences[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0151a4b-1887-4615-bb92-e82bc8a99b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When he first met the FTX founder Sam Bankman-Fried in late 2021, he took the cargo-shorted chief executive on a walk through the eucalyptus trees near his Berkeley, Calif., home.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.sentences[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c0ccf-23ab-4db1-8bce-9535e5792063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
